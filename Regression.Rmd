---
title: "Regression"
author: "Mark Hagemann"
date: "March 5, 2015"
output:
  beamer_presentation:
    incremental: yes
    keep_tex: true
    
---

```{r setup, echo = FALSE}
library(knitr)
library(ggplot2)
library(dplyr)
opts_chunk$set(echo = FALSE, warning = FALSE)
#if(!require(cats)) {devtools::install_github("hilaryparker/cats"); library(cats)}
```


## Outline

- What is a regression model and what's it good for?
    - Explanation
    - Quantifying relationships
    - Prediction
- Limitations
    - Assumptions (linearity, i.i.d., etc.)
    - Predicting is hard!

## Approach

- Look at your data
- build model(s)
- Check assumptions
- select model
- Use model

## Math background

## Linear functions

```{r linfun}
nn = 35
xdat = runif(nn, 0, 10)
b0 = 2
b1 = 1/2
sd = b1
set.seed(4321)
lindat = data.frame(x = xdat, y1 = xdat * b1 + b0, 
                    y2 = xdat * b1 + b0 + rnorm(nn, 0, sd),
                    y3 = xdat * b1 + b0 + rnorm(nn, 0, sd * 4))

g1 = ggplot(lindat, aes(x = x, y = y1)) + 
  scale_x_continuous(limits = c(0, 10)) + scale_y_continuous(limits = c(0, 10)) +
  geom_hline(aes(yintercept = 0), weight = 2) +
  geom_vline(aes(xintercept = 0), weight = 2) + 
  theme_minimal()
g1
```

## Linear functions
```{r}
# Linear function
g1 + geom_abline(aes(intercept = b0, slope = b1), show_guide = TRUE) + 
  annotate("text", x = 2, y = 5, label = paste0("a = ", b1, ", b = ", b0))

```

- $y = a \times x + b$

## Some (perfectly linear) data
``` {r}

# Some perfect linear data
g1 + geom_point(aes(x = x, y = y1))

```

## A (perfect) linear regression line
```{r}
# A perfect model for the data
g1 + geom_point(aes(x = x, y = y1)) + 
  geom_abline(aes(intercept = b0, slope = b1), show_guide = TRUE) + 
  annotate("text", x = 2, y = 5, label = paste0("a = ", b1, ", b = ", b0))

```

## More realistic case

```{r}
# In reality, we start with the (noisy) data, and we want to get the function

g2 = ggplot(lindat, aes(x = x, y = y2)) + 
  scale_x_continuous(limits = c(0, 10)) + scale_y_continuous(limits = c(0, 10)) +
  geom_hline(aes(yintercept = 0), weight = 2) +
  geom_vline(aes(xintercept = 0), weight = 2) + 
  theme_minimal()

g2 + geom_point()
```

### In reality, we start with the (noisy) data, and we seek the underlying function

## Fit a line
```{r}
g2  + geom_point() + stat_smooth(method = "lm")
```

## Compare to "actual" function
```{r}
g2 + geom_point() + stat_smooth(method = "lm") +
  geom_abline(aes(intercept = b0, slope = b1), linetype = 2)
```

## Impact of noise

```{r}
g3 = ggplot(lindat, aes(x = x, y = y3)) + 
  scale_x_continuous(limits = c(0, 10)) + scale_y_continuous(limits = c(-4, 10)) +
  geom_hline(aes(yintercept = 0), weight = 2) +
  geom_vline(aes(xintercept = 0), weight = 2) + 
  theme_minimal()

g3 + geom_point()
```

These data are 4 times noisier than the previous

## Now fit a line
```{r}

g3 + geom_point() + stat_smooth(method = "lm") +
  geom_abline(aes(intercept = b0, slope = b1), linetype = 2)

```

Dashed line is generating function.

## Back to the math: Regression function

### Different representations:

$$
Y = aX + b \\
Y = aX + b + (noise) \\
Y = \beta_0 + \beta_1 X + \epsilon \\
Y = \beta_0 + \sum_{i = 1}^p \beta_i X_i + \epsilon
$$


## Example: state demographics

```{r, echo = TRUE}
data(state)
kable(head(state.x77))
```

## Rename the columns
```{r, echo = TRUE}
state = state.x77 %>%
  as.data.frame() %>%
  setNames(c("pop", "inc", "illit", "lExp", "murder", "hsGrad", "frost", "area"))
kable(head(state))
```

## Inspect all pairwise relationships using `pairs()` function
```{r}
pairs(state)
```

## Make a model! For life expectancy...
```{r, echo = TRUE}
mod1 = lm(lExp ~ hsGrad, state)
mod2 = lm(lExp ~ murder + hsGrad, state)
mod3 = lm(lExp ~ murder + hsGrad + illit, state)
```

```{r}
pairs(state)
```

## See the good parts using `summary()`

## Model 1: 

```{r, echo = FALSE}
summary(mod1)
```


## Model 2: 

```{r, echo = FALSE}
summary(mod2)
```


## Model 3: 

```{r, echo = FALSE}
summary(mod3)
```


## Inspect the model!

### `termplot()` function

```{r, echo = TRUE}
par(mfrow = c(1, 2))
termplot(mod2, partial.resid = TRUE)
par(mfrow = c(1, 1))
```

## `qplot()` to look at residual distribution

```{r}
qplot(mod2$residuals, binwidth = 0.3)
```

- Could also use `hist()`, `qqnorm()`, etc.

## Make a prediction!

### `predict()` function
```{r, echo = TRUE}
newdat = data.frame(murder = 9, hsGrad = 77)
kable(newdat)
```

## Make a prediction!

### `predict()` function
```{r, echo = TRUE}
predict(mod2, newdat, se.fit = TRUE) %>%
  as.data.frame() %>%
  kable()
```

## Other topics:

- `glm()`
- `gam()` - **mgcv** package
- `arima()` - time series models
- automated model selection 
    - stepwise `step()` function, 
    - best subset **leaps** package
- machine learning methods - various packages

That's all!